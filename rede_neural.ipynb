{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Numérica - Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalando bibliotecas\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas\n",
    "import numpy as pd\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt \n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertendo dados - Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor é como uma matriz, mas não existe um limite de dimensões, podendo estar entre 0 a n. A biblioteca transforma os dados em tensor, por isso iremos realizar a transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "# definindo a imagem para tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# treino do dataset\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "# pegar os dados por parte\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# teste do dataset\n",
    "testset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
    "# pegar os dados por parte\n",
    "vallloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conferindo dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir um dos itens do dataset para visualizar formato\n",
    "dataiter = iter(trainloader)\n",
    "img, target = next(dataiter)\n",
    "plt.imshow(img[0].numpy().squeeze(), cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisando a dimensao do tensor imagem e tensor etiqueta\n",
    "# 1 = intensidade do preto em cada pixel\n",
    "# 28 = altura da imagem\n",
    "# 28 = largura da imagem\n",
    "print(img[0].shape)\n",
    "\n",
    "# etique nao possui dimensao por ser um escalar\n",
    "print(target[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando elementos da RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos 3 funções de ativação: ReLU, ReLU e SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(Modelo, self).__init__()\n",
    "        ## camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear1 = nn.Linear(784, 128)\n",
    "        ## camada oculta 1, 128 neurônios que se ligam a 64\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        ## camada oculta 2, 64 neurônios que se ligam a 10\n",
    "        self.linear3 = nn.Linear(64, 10)\n",
    "\n",
    "        # nao definimos a camada de saida pois pegamos ela a partir da camada 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        # camada de entrada \n",
    "        X = F.relu(self.linear1(X))\n",
    "        # camada oculta 1\n",
    "        X = F.relu(self.linear2(X))\n",
    "        # camada oculta 2\n",
    "        X = self.linear3(X)\n",
    "        # camada de saida\n",
    "        return F.log_softmax(X, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrutura de treino do modelo\n",
    "\n",
    "- Calcular a perda a partir da comparação entre as predições e as etiquetas(target) do subgrupo sendo analisado\n",
    "- Com a perda, calcular o gradiente em relação aos pesos e as bias\n",
    "- A partir do gradiente e de uma politica de otimização, atualizar os pesos e as bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador\n",
    "\n",
    "A partir do optim é possível escolher qual otimizador usar para fazer as atualizações dos pesos e do bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo funcao treino\n",
    "# interacao trainloader, back propagation e otimizador step sao repetidos ate que todo trainset seja percorrido   \n",
    "def treino(modelo, trainloader, device):\n",
    "    # definindo a funcao de perda e o otimizador do peso e do bias\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
    "    inicio = time()\n",
    "\n",
    "# definindo criterio para calcular a perda\n",
    "    criterio = nn.NLLLoss()\n",
    "    # numero de EPOCHS para treinar\n",
    "    EPOCHS = 30\n",
    "    # ativando treinamento do modelo\n",
    "    modelo.train()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0\n",
    "\n",
    "        for img, target in trainloader:\n",
    "            # convertendo as img para \"vetores\" 28*28 para serem compativeis com a entrada\n",
    "            img = img.view(img.shape[0], -1)\n",
    "            # zerando o gradiente para o proximo ciclo\n",
    "            otimizador.zero_grad()\n",
    "\n",
    "            # colocanndo os dados no modelo\n",
    "            output = modelo(img.to(device))\n",
    "            #calculando a perda da epoch atual\n",
    "            perda_instantanea = criterio(output, target.to(device))\n",
    "\n",
    "            # back propagation a partir da perda da epoch atual\n",
    "            perda_instantanea.backward()\n",
    "            # atualizando pesos e bias\n",
    "            otimizador.step()\n",
    "            #atualizacao da perda acumulada\n",
    "            perda_acumulada += perda_instantanea.item()\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "            print(\"\\nTempo de treino (em minutos) =\",(time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcão de otimizacao do modelo para teste\n",
    "def validacao(modelo, valloader, device):\n",
    "    contas_corretas, conta_todas = 0, 0\n",
    "    for img, target in valloader:\n",
    "        for i in range(len(target)):\n",
    "            imgs = img[i].view(1, 784)\n",
    "            # desativer autograd. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                # saida do modelo em escala logaritmica\n",
    "                logps = modelo(imgs.to(device))\n",
    "\n",
    "            # converte saida escala normal (tensor)\n",
    "            ps = torch.exp(logps)   \n",
    "            # probabilidade de cada classe\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            # converte o tensor em numero,  o numero que previu correto\n",
    "            pred_label = probab.index(max(probab))\n",
    "            pred_certa = target.numpy()[i]\n",
    "            # compara se o numero previsto é igual ao numero real\n",
    "            if(pred_certa  == pred_label):\n",
    "                contas_corretas += 1\n",
    "            conta_todas += 1\n",
    "\n",
    "    print(\"Numero de imagens testadas =\", conta_todas)\n",
    "    print(\"\\nNumero de imagens previstas corretamente =\", contas_corretas)\n",
    "    print(\"\\nAcuracia do modelo =\", (contas_corretas*100)/conta_todas, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializando o modelo\n",
    "modelo = Modelo()\n",
    "# definindo o dispositivo de processamento\n",
    "# modelo rodara na GPU se possivel, caso contrario, rodara na CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando o modelo\n",
    "treino(modelo, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validando o modelo\n",
    "validacao(modelo, vallloader, device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classificacao_numerica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
